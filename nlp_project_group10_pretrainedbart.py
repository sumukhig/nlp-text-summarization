# -*- coding: utf-8 -*-
"""NLP-Project-Group10-PreTrainedBART.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1odsXS0G3TWFFfhgdrcXKPSOwzp5UOI5H
"""

! pip install -U sentence_transformers

! pip install transformers datasets rouge-score

import os
import re
import numpy as np
import pandas as pd
import xml.etree.ElementTree as ET

from transformers import BartTokenizer, BartForConditionalGeneration
from rouge_score import rouge_scorer
from datasets import load_metric

# Extract text from XML
def extract_text_from_xml(xml_file_path):
    tree = ET.parse(xml_file_path)
    root = tree.getroot()

    def extract_text_data(element):
        text = (element.text or "").strip().lower()
        text = text.replace("quot", "")
        text = re.sub(r'https?://\S+', '', text)
        text = re.sub(r'[^\w\s]', '', text)

        return [text] + [t for e in element for t in extract_text_data(e)]

    all_data_text = list(filter(None, extract_text_data(root)))

    return all_data_text[1:]

# Extract text from summary .txt file
def extract_text_from_summary(summary_file_path):
    with open(summary_file_path, 'r') as f:
        return f.read()

# generate summary using BART model
def generate_summary(corpus):
    tokenizer = BartTokenizer.from_pretrained('facebook/bart-large-cnn')
    model = BartForConditionalGeneration.from_pretrained('facebook/bart-large-cnn')

    article = " ".join(corpus)
    inputs = tokenizer.encode("summarize: " + article, return_tensors='pt', max_length=1024, truncation=True)
    summary_ids = model.generate(inputs, max_length=150, min_length=40, length_penalty=2.0, num_beams=4, early_stopping=True)

    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)

# Evaluate the generated summary
def evaluate_summary(generated_summary, reference_summary):
    rouge = load_metric("rouge")
    scores = rouge.compute(predictions=[generated_summary], references=reference_summary)

    return {
        'rouge1': scores['rouge1'][0],
        'rouge2': scores['rouge2'][0],
        'rougeL': scores['rougeL'][0]
    }

# Evaluate the generated summary
def evaluate_and_save(corpus, xml_file, summary_file):
    generated_summary = generate_summary(corpus)
    reference_summary = extract_text_from_summary(summary_file)

    score = evaluate_summary(generated_summary, [reference_summary])
    results = {
        'File': os.path.basename(xml_file),
        'ROUGE-1 F1': score['rouge1'].fmeasure,
        'ROUGE-2 F1': score['rouge2'].fmeasure,
        'ROUGE-L F1': score['rougeL'].fmeasure
    }

    print(results)
    # Convert results to a df and append to csv
    df = pd.DataFrame([results])
    df.to_csv('rouge_scores.csv', mode='a', header=not os.path.exists('rouge_scores.csv'), index=False)

    return score['rouge1'].fmeasure


def main(directory):
    rouge_scores = []

    # Create or clear the csv if it already exists
    open('rouge_scores.csv', 'w').close()

    for article_dir in os.listdir(directory):
        article_path = os.path.join(directory, article_dir)

        if os.path.isdir(article_path):
            xml_dir = os.path.join(article_path, "Documents_xml")
            summary_dir = os.path.join(article_path, "summary")

            # Assuming there's only one xml and one txt file per dirs
            xml_file = next(os.path.join(xml_dir, f) for f in os.listdir(xml_dir) if f.endswith('.xml'))
            summary_file = next(os.path.join(summary_dir, f) for f in os.listdir(summary_dir) if f.endswith('.txt'))

            print(xml_file)
            corpus = extract_text_from_xml(xml_file)

            rouge_score = evaluate_and_save(corpus, xml_file, summary_file)
            rouge_scores.append(rouge_score)

    average_rouge_score = np.mean(rouge_scores)
    print(f"Average ROUGE-1 F1-Score: {average_rouge_score}")

# Call the main function with the path to articles
main("/content/drive/MyDrive/top1000_complete")